{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e38e690f-130d-48af-aed4-65c1be875d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "# uncomment below if running locally and wordcloud exists in your environment\n",
    "# from wordcloud import WordCloud \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171527ec-53a0-4173-ab14-d49e3e7b9701",
   "metadata": {},
   "source": [
    "### Process 2020 Social Media Post Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac0a7eb0-bf86-49b5-9112-d0a664d37d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_description</th>\n",
       "      <th>...</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_location</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>state</th>\n",
       "      <th>state_code</th>\n",
       "      <th>collected_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-15 00:00:01</td>\n",
       "      <td>1.316529221557252e+18</td>\n",
       "      <td>#Elecciones2020 | En #Florida: #JoeBiden dice ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TweetDeck</td>\n",
       "      <td>360666534.0</td>\n",
       "      <td>El Sol Latino News</td>\n",
       "      <td>elsollatinonews</td>\n",
       "      <td>üåê Noticias de inter√©s para latinos de la costa...</td>\n",
       "      <td>...</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>Philadelphia, PA / Miami, FL</td>\n",
       "      <td>25.77427</td>\n",
       "      <td>-80.19366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North America</td>\n",
       "      <td>Florida</td>\n",
       "      <td>FL</td>\n",
       "      <td>2020-10-21 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-15 00:00:02</td>\n",
       "      <td>1.316529228091847e+18</td>\n",
       "      <td>#Trump: As a student I used to hear for years,...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>8436472.0</td>\n",
       "      <td>snarke</td>\n",
       "      <td>snarke</td>\n",
       "      <td>Will mock for food! Freelance writer, blogger,...</td>\n",
       "      <td>...</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>Portland</td>\n",
       "      <td>45.5202471</td>\n",
       "      <td>-122.6741949</td>\n",
       "      <td>Portland</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North America</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>OR</td>\n",
       "      <td>2020-10-21 00:00:00.746433060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-15 00:00:08</td>\n",
       "      <td>1.3165292523014513e+18</td>\n",
       "      <td>You get a tie! And you get a tie! #Trump ‚Äòs ra...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>47413798.0</td>\n",
       "      <td>Rana Abtar - ÿ±ŸÜÿß ÿ£ÿ®ÿ™ÿ±</td>\n",
       "      <td>Ranaabtar</td>\n",
       "      <td>Washington Correspondent, Lebanese-American ,c...</td>\n",
       "      <td>...</td>\n",
       "      <td>5393.0</td>\n",
       "      <td>Washington DC</td>\n",
       "      <td>38.8949924</td>\n",
       "      <td>-77.0365581</td>\n",
       "      <td>Washington</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North America</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>DC</td>\n",
       "      <td>2020-10-21 00:00:01.492866121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-15 00:00:17</td>\n",
       "      <td>1.316529291052675e+18</td>\n",
       "      <td>@CLady62 Her 15 minutes were over long time ag...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>1138416104.0</td>\n",
       "      <td>Farris Flagg</td>\n",
       "      <td>FarrisFlagg</td>\n",
       "      <td>#BidenHarris2020 #JoeBiden2020 #KamalaHarrisFo...</td>\n",
       "      <td>...</td>\n",
       "      <td>2363.0</td>\n",
       "      <td>Perris,California</td>\n",
       "      <td>33.7825194</td>\n",
       "      <td>-117.22864779999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North America</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>2020-10-21 00:00:01.866082651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-15 00:00:18</td>\n",
       "      <td>1.3165292934979625e+18</td>\n",
       "      <td>@DeeviousDenise @realDonaldTrump @nypost There...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>9.007610716314296e+17</td>\n",
       "      <td>Stacey Gulledge üá∫üá∏ Patriot ‚ô•Ô∏è KAG üôè üëÆ‚Äç‚ôÄÔ∏è‚ô•Ô∏è</td>\n",
       "      <td>sm_gulledge</td>\n",
       "      <td>Patriot, Wife, ‚ÄúShaken not Stirred‚Äù Mom of two...</td>\n",
       "      <td>...</td>\n",
       "      <td>766.0</td>\n",
       "      <td>Ohio, USA</td>\n",
       "      <td>40.225356899999994</td>\n",
       "      <td>-82.6881395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North America</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>OH</td>\n",
       "      <td>2020-10-21 00:00:02.612515712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at                tweet_id  \\\n",
       "0  2020-10-15 00:00:01   1.316529221557252e+18   \n",
       "1  2020-10-15 00:00:02   1.316529228091847e+18   \n",
       "2  2020-10-15 00:00:08  1.3165292523014513e+18   \n",
       "3  2020-10-15 00:00:17   1.316529291052675e+18   \n",
       "4  2020-10-15 00:00:18  1.3165292934979625e+18   \n",
       "\n",
       "                                               tweet likes  retweet_count  \\\n",
       "0  #Elecciones2020 | En #Florida: #JoeBiden dice ...   0.0            0.0   \n",
       "1  #Trump: As a student I used to hear for years,...   2.0            1.0   \n",
       "2  You get a tie! And you get a tie! #Trump ‚Äòs ra...   4.0            3.0   \n",
       "3  @CLady62 Her 15 minutes were over long time ag...   2.0            0.0   \n",
       "4  @DeeviousDenise @realDonaldTrump @nypost There...   0.0            0.0   \n",
       "\n",
       "                source                user_id  \\\n",
       "0            TweetDeck            360666534.0   \n",
       "1      Twitter Web App              8436472.0   \n",
       "2   Twitter for iPhone             47413798.0   \n",
       "3  Twitter for Android           1138416104.0   \n",
       "4   Twitter for iPhone  9.007610716314296e+17   \n",
       "\n",
       "                                    user_name user_screen_name  \\\n",
       "0                          El Sol Latino News  elsollatinonews   \n",
       "1                                      snarke           snarke   \n",
       "2                       Rana Abtar - ÿ±ŸÜÿß ÿ£ÿ®ÿ™ÿ±        Ranaabtar   \n",
       "3                                Farris Flagg      FarrisFlagg   \n",
       "4  Stacey Gulledge üá∫üá∏ Patriot ‚ô•Ô∏è KAG üôè üëÆ‚Äç‚ôÄÔ∏è‚ô•Ô∏è      sm_gulledge   \n",
       "\n",
       "                                    user_description  ...  \\\n",
       "0  üåê Noticias de inter√©s para latinos de la costa...  ...   \n",
       "1  Will mock for food! Freelance writer, blogger,...  ...   \n",
       "2  Washington Correspondent, Lebanese-American ,c...  ...   \n",
       "3  #BidenHarris2020 #JoeBiden2020 #KamalaHarrisFo...  ...   \n",
       "4  Patriot, Wife, ‚ÄúShaken not Stirred‚Äù Mom of two...  ...   \n",
       "\n",
       "  user_followers_count                 user_location                 lat  \\\n",
       "0               1860.0  Philadelphia, PA / Miami, FL            25.77427   \n",
       "1               1185.0                      Portland          45.5202471   \n",
       "2               5393.0                 Washington DC          38.8949924   \n",
       "3               2363.0             Perris,California          33.7825194   \n",
       "4                766.0                     Ohio, USA  40.225356899999994   \n",
       "\n",
       "                  long        city                   country      continent  \\\n",
       "0            -80.19366         NaN  United States of America  North America   \n",
       "1         -122.6741949    Portland  United States of America  North America   \n",
       "2          -77.0365581  Washington  United States of America  North America   \n",
       "3  -117.22864779999999         NaN  United States of America  North America   \n",
       "4          -82.6881395         NaN  United States of America  North America   \n",
       "\n",
       "                  state state_code                   collected_at  \n",
       "0               Florida         FL            2020-10-21 00:00:00  \n",
       "1                Oregon         OR  2020-10-21 00:00:00.746433060  \n",
       "2  District of Columbia         DC  2020-10-21 00:00:01.492866121  \n",
       "3            California         CA  2020-10-21 00:00:01.866082651  \n",
       "4                  Ohio         OH  2020-10-21 00:00:02.612515712  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the file path\n",
    "file_path = \"../Source_data/posts_2020.csv\"\n",
    "\n",
    "# Initialize an empty DataFrame to hold the filtered data\n",
    "posts_2020_df = pd.DataFrame()\n",
    "\n",
    "# Define the acceptable values for the 'country' column\n",
    "acceptable_countries = [\"United States\", \"United States of America\"]\n",
    "\n",
    "# Process the file in chunks to handle large files\n",
    "chunk_size = 10**6  # Adjust the chunk size based on your system's memory capacity\n",
    "for chunk in pd.read_csv(\n",
    "    file_path,\n",
    "    engine='python',                  # Use Python engine to handle more complex cases\n",
    "    on_bad_lines='skip',              # Skip problematic lines\n",
    "    delimiter=',',                    # Ensure correct delimiter\n",
    "    chunksize=chunk_size              # Read the file in chunks\n",
    "):\n",
    "    # Filter rows based on the 'country' column\n",
    "    filtered_chunk = chunk[chunk['country'].isin(acceptable_countries)]\n",
    "    # Append the filtered chunk to the main DataFrame\n",
    "    posts_2020_df = pd.concat([posts_2020_df, filtered_chunk], ignore_index=True)\n",
    "\n",
    "# Verify the result\n",
    "posts_2020_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e0d499-299a-481f-b4fd-00e2c14f4f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>handle</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.316529221557252e+18</td>\n",
       "      <td>elsollatinonews</td>\n",
       "      <td>#Elecciones2020 | En #Florida: #JoeBiden dice ...</td>\n",
       "      <td>2020-10-15 00:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.316529228091847e+18</td>\n",
       "      <td>snarke</td>\n",
       "      <td>#Trump: As a student I used to hear for years,...</td>\n",
       "      <td>2020-10-15 00:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3165292523014513e+18</td>\n",
       "      <td>Ranaabtar</td>\n",
       "      <td>You get a tie! And you get a tie! #Trump ‚Äòs ra...</td>\n",
       "      <td>2020-10-15 00:00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.316529291052675e+18</td>\n",
       "      <td>FarrisFlagg</td>\n",
       "      <td>@CLady62 Her 15 minutes were over long time ag...</td>\n",
       "      <td>2020-10-15 00:00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.3165292934979625e+18</td>\n",
       "      <td>sm_gulledge</td>\n",
       "      <td>@DeeviousDenise @realDonaldTrump @nypost There...</td>\n",
       "      <td>2020-10-15 00:00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id           handle  \\\n",
       "0   1.316529221557252e+18  elsollatinonews   \n",
       "1   1.316529228091847e+18           snarke   \n",
       "2  1.3165292523014513e+18        Ranaabtar   \n",
       "3   1.316529291052675e+18      FarrisFlagg   \n",
       "4  1.3165292934979625e+18      sm_gulledge   \n",
       "\n",
       "                                                text                 time  \n",
       "0  #Elecciones2020 | En #Florida: #JoeBiden dice ...  2020-10-15 00:00:01  \n",
       "1  #Trump: As a student I used to hear for years,...  2020-10-15 00:00:02  \n",
       "2  You get a tie! And you get a tie! #Trump ‚Äòs ra...  2020-10-15 00:00:08  \n",
       "3  @CLady62 Her 15 minutes were over long time ag...  2020-10-15 00:00:17  \n",
       "4  @DeeviousDenise @realDonaldTrump @nypost There...  2020-10-15 00:00:18  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restrict dataframe to columns of interest\n",
    "\n",
    "# Rename columns\n",
    "posts_2020_df.rename(columns={\n",
    "    'user_screen_name': 'handle',\n",
    "    'tweet': 'text',\n",
    "    'created_at': 'time',\n",
    "    'tweet_id': 'id'\n",
    "}, inplace=True)\n",
    "\n",
    "# Select only the required columns\n",
    "posts_2020_df = posts_2020_df[['id', 'handle', 'text', 'time']]\n",
    "\n",
    "# Verify the result\n",
    "posts_2020_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a10b9b67-13a3-41df-bef2-918073982b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>#Elecciones2020 | En #Florida: #JoeBiden dice ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5905</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.929</td>\n",
       "      <td>#Trump: As a student I used to hear for years,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>You get a tie! And you get a tie! #Trump ‚Äòs ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.4912</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.874</td>\n",
       "      <td>@CLady62 Her 15 minutes were over long time ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.2617</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.866</td>\n",
       "      <td>@DeeviousDenise @realDonaldTrump @nypost There...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Compound  Positive  Negative  Neutral  \\\n",
       "0    0.0000     0.000     0.000    1.000   \n",
       "1    0.5905     0.071     0.000    0.929   \n",
       "2    0.0000     0.000     0.000    1.000   \n",
       "3   -0.4912     0.000     0.126    0.874   \n",
       "4   -0.2617     0.056     0.078    0.866   \n",
       "\n",
       "                                                text  \n",
       "0  #Elecciones2020 | En #Florida: #JoeBiden dice ...  \n",
       "1  #Trump: As a student I used to hear for years,...  \n",
       "2  You get a tie! And you get a tie! #Trump ‚Äòs ra...  \n",
       "3  @CLady62 Her 15 minutes were over long time ag...  \n",
       "4  @DeeviousDenise @realDonaldTrump @nypost There...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments20 = []\n",
    "\n",
    "for comment in posts_2020_df['text']:\n",
    "    try:\n",
    "        # Ensure comment is a string\n",
    "        if not isinstance(comment, str):\n",
    "            raise ValueError(\"Comment is not a string\")\n",
    "            \n",
    "        results = analyzer.polarity_scores(comment)\n",
    "               \n",
    "        sentiments20.append({\n",
    "            'Compound': results['compound'],\n",
    "            'Positive': results['pos'],\n",
    "            'Negative': results['neg'],\n",
    "            'Neutral': results['neu'],\n",
    "            'text': comment,\n",
    "        })\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "sm20 = pd.DataFrame(sentiments20)\n",
    "sm20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09037b29-d964-4b9f-97bf-ad58ada01775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>213259.000000</td>\n",
       "      <td>213259.000000</td>\n",
       "      <td>213259.000000</td>\n",
       "      <td>213259.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.009011</td>\n",
       "      <td>0.080170</td>\n",
       "      <td>0.080945</td>\n",
       "      <td>0.838883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.476845</td>\n",
       "      <td>0.105996</td>\n",
       "      <td>0.110512</td>\n",
       "      <td>0.145215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.999500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.361200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.741000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.848000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.361200</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>0.141000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Compound       Positive       Negative        Neutral\n",
       "count  213259.000000  213259.000000  213259.000000  213259.000000\n",
       "mean       -0.009011       0.080170       0.080945       0.838883\n",
       "std         0.476845       0.105996       0.110512       0.145215\n",
       "min        -0.999500       0.000000       0.000000       0.012000\n",
       "25%        -0.361200       0.000000       0.000000       0.741000\n",
       "50%         0.000000       0.024000       0.000000       0.848000\n",
       "75%         0.361200       0.138000       0.141000       1.000000\n",
       "max         0.998700       0.958000       0.988000       1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary statistics sm20\n",
    "sm20.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d1d8ea-397b-40f6-81e6-3185ff04727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export CSV file with summary info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe08bd6-f302-40e8-8bcf-809c11c4d9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff33486-f8a2-4e9a-b77b-eef945d61c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "444286bf-103f-40a4-bc82-8ea503b69d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>token_count</th>\n",
       "      <th>avg_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trump</td>\n",
       "      <td>1033</td>\n",
       "      <td>-0.040622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>830</td>\n",
       "      <td>-0.056141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>581</td>\n",
       "      <td>0.002248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https</td>\n",
       "      <td>575</td>\n",
       "      <td>-0.140759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>384</td>\n",
       "      <td>-0.014446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   token  token_count  avg_sentiment\n",
       "0  trump         1033      -0.040622\n",
       "1    the          830      -0.056141\n",
       "2     to          581       0.002248\n",
       "3  https          575      -0.140759\n",
       "4      a          384      -0.014446"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate sentiment score for the entire text\n",
    "def get_text_sentiment(text):\n",
    "    return analyzer.polarity_scores(text)['compound']\n",
    "\n",
    "# Function to tokenize text and return only alphabetic tokens\n",
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    return [token for token in tokens if token.isalpha()]\n",
    "\n",
    "# Process chunks of data to avoid memory issues\n",
    "def process_chunk(chunk):\n",
    "    chunk = chunk.copy()  # Make a copy to avoid SettingWithCopyWarning\n",
    "    \n",
    "    # Calculate text sentiment\n",
    "    chunk['text_sentiment'] = chunk['text'].apply(get_text_sentiment)\n",
    "    \n",
    "    # Tokenize and explode tokens\n",
    "    tokens_df = chunk['text'].apply(lambda x: tokenize_text(x))\n",
    "    tokens_exploded = tokens_df.explode().reset_index(drop=True)\n",
    "    tokens_exploded.name = 'token'\n",
    "    tokens_exploded = tokens_exploded.to_frame().join(chunk[['text_sentiment']].reset_index(drop=True), how='left')\n",
    "    \n",
    "    # Calculate token counts and average sentiment\n",
    "    token_counts = tokens_exploded['token'].value_counts().reset_index()\n",
    "    token_counts.columns = ['token', 'token_count']\n",
    "    token_sentiments = tokens_exploded.groupby('token')['text_sentiment'].mean().reset_index(name='avg_sentiment')\n",
    "    \n",
    "    # Merge counts and sentiments\n",
    "    token_summary = pd.merge(token_counts, token_sentiments, on='token')\n",
    "    \n",
    "    return token_summary\n",
    "\n",
    "# Create a generator for processing chunks\n",
    "def chunk_generator(df, chunk_size):\n",
    "    for start in range(0, len(df), chunk_size):\n",
    "        yield df.iloc[start:start + chunk_size].copy()\n",
    "\n",
    "# Process data in chunks\n",
    "chunk_size = 1000  # Adjust chunk size based on available memory\n",
    "processed_chunks = [process_chunk(chunk) for chunk in chunk_generator(posts_2020_df, chunk_size)]\n",
    "sm20_processed = pd.concat(processed_chunks, ignore_index=True)\n",
    "\n",
    "# Clean up memory\n",
    "del processed_chunks\n",
    "gc.collect()\n",
    "\n",
    "# View the processed DataFrame\n",
    "sm20_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d238612-1cb4-4179-8093-48f26d9b12a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to align with the `sm20_with_candidates`\n",
    "# For demonstration, assuming that sm20_with_candidates has 'text' and 'candidate' columns.\n",
    "def expand_with_candidates(df):\n",
    "    # Explode the token column\n",
    "    token_expanded = df.explode('token').reset_index(drop=True)\n",
    "    \n",
    "    # Merge with the original sentiment DataFrame\n",
    "    df_expanded = pd.merge(token_expanded, sm20_with_candidates[['text', 'candidate']], on='text', how='left')\n",
    "    \n",
    "    # Calculate unique token counts for each candidate\n",
    "    unique_token_counts = df_expanded.groupby(['candidate', 'token']).size().reset_index(name='unique_token_count')\n",
    "    \n",
    "    # Merge with average sentiment scores\n",
    "    final_df = pd.merge(df_expanded, unique_token_counts, on=['candidate', 'token'], how='left')\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Call the function to expand with candidates\n",
    "token_sentiments_2020 = expand_with_candidates(sm20_processed)\n",
    "\n",
    "# View the final DataFrame\n",
    "print(token_sentiments_2020.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21021601-348d-43c3-b3ea-ac48ce4f1840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacbc521-e5fa-43f5-8516-7a05e9b8c57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average sentiment score per token\n",
    "average_sentiments_2020 = sm20_processed.sort_values(by='avg_sentiment', ascending=False).reset_index(drop=True)\n",
    "print(\"Average sentiment scores per token for 2020:\")\n",
    "print(average_sentiments_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5daf4e3-af01-41a8-93f1-d636e1defb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out tokens that are not English words\n",
    "english_words = set(words.words())\n",
    "filtered_tokens_df = sm20_processed[sm20_processed['token'].isin(english_words)]\n",
    "\n",
    "# Sort by average sentiment in descending order\n",
    "average_sentiments_2020 = filtered_tokens_df.sort_values(by='avg_sentiment', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Average sentiment scores per token for 2020 (filtered for English words):\")\n",
    "print(average_sentiments_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b015889-a5d4-4f2d-90b1-16a1092a71dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to determine the candidate based on keywords in the text\n",
    "def determine_candidate(text):\n",
    "    text = text.lower()\n",
    "    republican_keywords = ['trump', 'donald']\n",
    "    democrat_keywords = ['joe', 'biden']\n",
    "    \n",
    "    if any(keyword in text for keyword in democrat_keywords):\n",
    "        return 'democrat'\n",
    "    elif any(keyword in text for keyword in republican_keywords):\n",
    "        return 'republican'\n",
    "    else:\n",
    "        return 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5988194-866a-43cb-ad7c-1ef84a053299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the 'text' column of posts_2020_df to create the 'candidate' column\n",
    "posts_2020_df['candidate'] = posts_2020_df['text'].apply(determine_candidate)\n",
    "\n",
    "# Verify the result\n",
    "posts_2020_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe95af-58e1-44f3-a5d7-b4b68bb203bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove entries where the 'candidate' column is 'Unknown'\n",
    "posts_2020_df = posts_2020_df[posts_2020_df['candidate'] != 'Unknown']\n",
    "\n",
    "# Verify the result\n",
    "posts_2020_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7ba57a-3ca5-4464-9cc8-9159da7afa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of 'Unknown' entries in the 'candidate' column\n",
    "unknown_count = posts_2020_df['candidate'].value_counts().get('Unknown', 0)\n",
    "\n",
    "print(f\"Number of 'Unknown' entries: {unknown_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bb6f3b-6cd4-4d63-bd29-25e9fdff8965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize text\n",
    "def tokenize_text(text):\n",
    "    # Your implementation for tokenizing text\n",
    "    tokens = word_tokenize(text.lower())  # Tokenize and convert to lower case\n",
    "    return [token for token in tokens if token.isalpha()]  # Return only alphabetic tokens\n",
    "\n",
    "# Function to process each chunk\n",
    "def process_chunk(chunk, token_sentiments_df):\n",
    "    # Explode tokens in the chunk\n",
    "    chunk['tokens'] = chunk['text'].apply(tokenize_text)\n",
    "    chunk_expanded = chunk.explode('tokens')\n",
    "    chunk_expanded.rename(columns={'tokens': 'token'}, inplace=True)\n",
    "    \n",
    "    # Merge with token sentiments data\n",
    "    merged_chunk = chunk_expanded.merge(token_sentiments_df, on='token', how='left')\n",
    "    \n",
    "    # Aggregate sentiment values and token counts by candidate and token\n",
    "    token_sentiments_chunk = merged_chunk.groupby(['candidate', 'token']).agg({\n",
    "        'sentiment_value': 'mean',\n",
    "        'unique_token_count': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    return token_sentiments_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493ac695-aec1-4399-8ad5-9a9e37ecbb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to hold the aggregated results\n",
    "aggregated_results = pd.DataFrame()\n",
    "\n",
    "# Process data in chunks\n",
    "num_chunks = len(sm20_with_candidates) // chunk_size + 1\n",
    "for i in range(num_chunks):\n",
    "    start = i * chunk_size\n",
    "    end = min((i + 1) * chunk_size, len(sm20_with_candidates))\n",
    "    chunk = sm20_with_candidates.iloc[start:end].copy()  # Make a copy to avoid SettingWithCopyWarning\n",
    "    \n",
    "    token_sentiments_chunk = process_chunk(chunk, sm20_processed)\n",
    "    \n",
    "    # Append the results for each chunk\n",
    "    aggregated_results = pd.concat([aggregated_results, token_sentiments_chunk], ignore_index=True)\n",
    "    \n",
    "    # Clean up memory\n",
    "    del chunk, token_sentiments_chunk\n",
    "    gc.collect()\n",
    "\n",
    "# Final aggregation to ensure no duplicates and accurate counts\n",
    "final_results = aggregated_results.groupby(['candidate', 'token']).agg({\n",
    "    'sentiment_value': 'mean',\n",
    "    'unique_token_count': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Verify the result\n",
    "final_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562dae7c-e377-46c7-b6f1-d23c9897b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge sm20 with posts_2020_df on the 'text' column to add 'candidate'\n",
    "sm20_with_candidates = pd.merge(sm20, posts_2020_df[['text', 'candidate']], on='text', how='left')\n",
    "\n",
    "# View dataframe\n",
    "sm20_with_candidates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0469419c-7832-48e2-83d4-36617b930838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify all token columns\n",
    "token_columns = [col for col in sm20_with_candidates.columns if col.startswith('token_')]\n",
    "\n",
    "# Ensure that the value name does not match any existing column names\n",
    "# Checking for potential conflicts\n",
    "existing_columns = set(sm20_with_candidates.columns)\n",
    "unique_value_name = 'token_count' if 'token_count' not in existing_columns else 'token_count_unique'\n",
    "\n",
    "# Reshape the DataFrame from wide to long format for tokens\n",
    "tokens_long_df = sm16_with_candidates.melt(\n",
    "    id_vars=['text', 'candidate'], \n",
    "    value_vars=token_columns,\n",
    "    var_name='token',\n",
    "    value_name=unique_value_name\n",
    ")\n",
    "\n",
    "# Filter out rows where token_count is 0\n",
    "tokens_long_df = tokens_long_df[tokens_long_df[unique_value_name] > 0]\n",
    "\n",
    "# Melt sentiment columns to long format\n",
    "sentiment_columns = ['Compound', 'Positive', 'Negative', 'Neutral']\n",
    "sentiments_long_df = sm16_with_candidates.melt(\n",
    "    id_vars=['text', 'candidate'],\n",
    "    value_vars=sentiment_columns,\n",
    "    var_name='sentiment_type',\n",
    "    value_name='sentiment_value'\n",
    ")\n",
    "\n",
    "# Merge token presence with sentiment values on 'text' and 'candidate'\n",
    "merged_df = tokens_long_df.merge(sentiments_long_df, on=['text', 'candidate'])\n",
    "\n",
    "# Aggregate sentiment values by candidate and token\n",
    "token_sentiments_2016 = merged_df.groupby(['candidate', 'token']).agg({\n",
    "    'sentiment_value': 'mean',\n",
    "    unique_value_name: 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Verify the result\n",
    "token_sentiments_2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64cbaf4-190b-4f07-bacf-a87132072ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sentiment scores by candidate\n",
    "\n",
    "# Calculate weighted average sentiment score for each candidate\n",
    "# This step uses the 'sentiment_value' and 'token_count_unique' columns\n",
    "candidate_sentiments = token_sentiments_2016.groupby('candidate').apply(\n",
    "    lambda df: (df['sentiment_value'] * df['token_count_unique']).sum() / df['token_count_unique'].sum()\n",
    ").reset_index(name='average_sentiment')\n",
    "\n",
    "# Display the aggregated sentiment scores\n",
    "print(\"Average sentiment scores by candidate:\")\n",
    "print(candidate_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ed858-0111-4051-8695-eed47802b006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine sentiment scores with other features\n",
    "\n",
    "# Merge candidate sentiments with posts_2016_df\n",
    "# Make sure to use the 'candidate' column for merging\n",
    "sent_2016_df = pd.merge(posts_2016_df, candidate_sentiments, on='candidate', how='left')\n",
    "\n",
    "# Display the final DataFrame with the required columns\n",
    "sent_2016_df = sent_2016_df[['id', 'text', 'time', 'candidate', 'average_sentiment']]\n",
    "sent_2016_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad53ec6-749b-401d-aa0c-a401c74f7198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the time column to display only the year\n",
    "\n",
    "# Ensure the 'time' column is in datetime format\n",
    "sent_2016_df['time'] = pd.to_datetime(sent_2016_df['time'], errors='coerce')\n",
    "\n",
    "# Extract the year from the datetime column and update the 'time' column\n",
    "sent_2016_df['time'] = sent_2016_df['time'].dt.year\n",
    "\n",
    "# Display the modified DataFrame\n",
    "sent_2016_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee261efe-5309-4e39-b6bd-9b54f75fd1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final 2016 DataFrame to a CSV file\n",
    "sent_2016_df.to_csv('../CSV_Outputs/sent_2016_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c269c9-8bdb-40ac-9e6e-a4d940922169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average sentiment scores for each candidate\n",
    "\n",
    "# Define color palette to match the colleague's visual\n",
    "color_palette = {'Democrat': 'blue', 'Republican': 'red'}\n",
    "\n",
    "# Create a seaborn bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='candidate', y='average_sentiment', data=candidate_sentiments, palette=color_palette)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Candidate')\n",
    "plt.ylabel('Average Sentiment Score')\n",
    "plt.title('Average Sentiment Score by Candidate')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c8d6e0-9201-4d2f-a83f-b04dd55b872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display positive, negative, and neutral sentiment scores by candidate\n",
    "\n",
    "# Aggregate sentiment scores by candidate\n",
    "sentiment_summary = sm16_with_candidates.groupby('candidate')[['Positive', 'Negative', 'Neutral']].sum().reset_index()\n",
    "\n",
    "# Define color palette for sentiments\n",
    "color_palettes = {\n",
    "    'Democrat': {\n",
    "        'Positive': 'blue',  # Replace 'strongblue' with actual color code\n",
    "        'Negative': 'lightblue',   # Replace 'palerblue' with actual color code\n",
    "        'Neutral': 'lightgrey'\n",
    "    },\n",
    "    'Republican': {\n",
    "        'Positive': 'darkred',     # Strong red\n",
    "        'Negative': 'lightcoral',  # Pale red\n",
    "        'Neutral': 'lightgrey'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define a function to plot a pie chart for a given candidate\n",
    "def plot_pie_chart(candidate, positive, negative, neutral):\n",
    "    sentiments = [positive, negative, neutral]\n",
    "    labels = ['Positive', 'Negative', 'Neutral']\n",
    "    colors = color_palettes.get(candidate, {\n",
    "        'Positive': 'grey',\n",
    "        'Negative': 'grey',\n",
    "        'Neutral': 'grey'\n",
    "    }).values()\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pie(sentiments, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
    "    plt.title(f'Sentiment Distribution for {candidate}')\n",
    "    plt.show()\n",
    "\n",
    "# Plot pie charts for each candidate\n",
    "for index, row in sentiment_summary.iterrows():\n",
    "    candidate = row['candidate']\n",
    "    positive = row['Positive']\n",
    "    negative = row['Negative']\n",
    "    neutral = row['Neutral']\n",
    "    plot_pie_chart(candidate, positive, negative, neutral)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988768df-2c74-43b8-aae0-3c6db50fde78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Word Cloud by candidate (uncomment below if running in CoLab)\n",
    "\n",
    "# !pip install wordcloud\n",
    "# from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f00b71c-7e58-4688-b122-22eaf64de73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate token counts by candidate\n",
    "token_frequencies = token_sentiments_2016.groupby('candidate')['token_count'].sum().reset_index()\n",
    "\n",
    "# Define a function to generate and display a word cloud for a given candidate\n",
    "def generate_word_cloud(candidate, token_counts):\n",
    "    # Create a dictionary of token frequencies\n",
    "    token_freq_dict = dict(zip(token_counts['token'], token_counts['token_count']))\n",
    "    \n",
    "    # Generate word cloud\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='Blues').generate_from_frequencies(token_freq_dict)\n",
    "    \n",
    "    # Plot word cloud\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')  # No axes for word cloud\n",
    "    plt.title(f'Word Cloud for {candidate}')\n",
    "    plt.show()\n",
    "\n",
    "# Generate word clouds for each candidate\n",
    "candidates = token_sentiments_2016['candidate'].unique()\n",
    "for candidate in candidates:\n",
    "    # Filter token counts for the current candidate\n",
    "    candidate_tokens = token_sentiments_2016[token_sentiments_2016['candidate'] == candidate]\n",
    "    \n",
    "    # Generate and display word cloud\n",
    "    generate_word_cloud(candidate, candidate_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c92a1d-bc03-4d3b-b2df-b12edd384324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
