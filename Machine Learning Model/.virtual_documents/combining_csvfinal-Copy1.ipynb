





import pandas as pd
import glob



# Read in files
df1 = pd.read_csv('../Census_demo/FinalCensusCsv/reduced_age_census.csv')
df1.head()


df1.columns


# Read in files
df2 = pd.read_csv('../CSV_Outputs/average_sentiment_by_party_all_years.csv')
df2


# Read in files
df3 = pd.read_csv('../Economic Indicators/Economic_Election.csv')
df3


# dropped unnecessary columns
df3_cleaned = df3.drop(columns=['candidate'])


# Remove rows where 'state' column value is "united states" since most values were NaN and it was not a necessary value
df3_updated = df3_cleaned[df3_cleaned['state_country'] != "United States"]



# Pivot the DataFrame to move the economic indicators to be features instead of values.
pivot_df = df3_updated.pivot_table(index=['state_country', 'total_votes', 'party', 'percent', 'election_year'],
                         columns='economic_indicator', values='value')

# Reset index if you want to flatten the DataFrame
pivot_df.reset_index(inplace=True)
pivot_df.head()


# read in files
df4 = pd.read_csv('../Census_demo/FinalCensusCsv/merged_race_data2.csv')
df4.head()



# dropped more features to further reduce dataset size and as much as I wanted to feature them, the values were on average low enough to focus on the higher percentages that may affect the data more
df4_cleaned = df4.drop(columns=['american_indian_and_alaska_native','asian','native_hawaiian_and_other_pacific-islander'])
df4_cleaned.head()


# Rename the 'election_year' column to 'Year' to help merge later
pivot_df.rename(columns={'election_year': 'Year'}, inplace=True)
pivot_df.rename(columns={'state_country': 'state'}, inplace=True)

# Display the DataFrame to confirm the change
pivot_df.head()




# Checked data types to prep for merge
pivot_df.dtypes


# Merge DataFrames on the 'year' column with different column names
merged_df = pd.merge(df2, pivot_df, on='Year', how='outer')

# Display the first few rows of the merged DataFrame
merged_df.head(50)



merged_df.dtypes


# Drop the 'Candidate' column from the DataFrame
merged_df = merged_df.drop(columns=['Candidate'])

# Display the DataFrame to confirm the column has been dropped
merged_df.head()



merged_df.head(50)


df1.head(50)


# Merge with df1 on 'state'
merged_with_df1 = pd.merge(merged_df, df1, on='state', how='outer')
merged_with_df1.head(50)


merged_with_df1.tail(50)


# Merge with df4 on 'state'
final_merged_df = pd.merge(merged_with_df1, df4_cleaned, on='state', how='outer')


final_merged_df.head(50)


# Final merge and changed feature name of 'party' to 'winner' as that what the values represented
final_merged_df = final_merged_df.rename(columns={'party': 'winner'})

#  Change values in the 'winner' column so the model can better feed them in and interpret them
final_merged_df['winner'] = final_merged_df['winner'].map({'Democrat': 0, 'Republican': 1})

#  Move the 'winner' column to the end
# Reorder columns
final_merged_df = final_merged_df[[col for col in final_merged_df.columns if col != 'winner'] + ['winner']]


final_merged_df.head(50)


final_merged_df.dtypes


# Drop 'year_x' and 'year_y' columns from the DataFrame
final_merged_df = final_merged_df.drop(columns=['year_x', 'year_y'])



final_merged_df.dtypes


# Fill NaN values with 'Unknown'
final_merged_df['state'] = final_merged_df['state'].fillna('Unknown')



# Perform encoding after handling NaN values
cat_df_encoded = pd.get_dummies(final_merged_df, columns=['state'])


# Impute NaN values with the median of each column
cat_df_encoded.fillna(cat_df_encoded.median(), inplace=True)



# Check for any NaN values
has_nan = cat_df_encoded.isna().any().any()
print("DataFrame contains NaN values:", has_nan)



# Shows rows with NaN values in any column
nan_rows = cat_df_encoded[cat_df_encoded.isna().any(axis=1)]
print(nan_rows)



# Checking for null values
has_nan = cat_df_encoded.isna().any().any()
print("DataFrame contains NaN values:", has_nan)


cat_df_encoded.head(50)


cat_df_encoded.columns


# Filling null values with either surrounding data or inplace value
cat_df_encoded.fillna(method='ffill', inplace=True)
cat_df_encoded.fillna(method='bfill', inplace=True)
cat_df_encoded.fillna(0, inplace=True)  



print(cat_df_encoded.isna().any().any())



# Export the cleaned DataFrame to a CSV file
cat_df_encoded.to_csv('prediction_final_df.csv', index=False)








from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score


# Define the years for training and testing sets
#train_years = [2008, 2012, 2016, 2020]
#test_years = [2022, 2024]

# Create training and testing DataFrames based on the year criteria
#train_df = cat_df_encoded[cat_df_encoded['Year'].isin(train_years)]
#test_df = cat_df_encoded[cat_df_encoded['Year'].isin(test_years)]

# Check columns to ensure proper split
#print("Training DataFrame columns:", train_df.columns)
#print("Testing DataFrame columns:", test_df.columns)

# Verify that the years used for training and testing are present in the DataFrame
train_years = [2008, 2012, 2016]
test_years = [2020, 2024]

# Check if these years exist in the DataFrame
years_in_df = cat_df_encoded['Year'].unique()
print(f"Years in DataFrame: {years_in_df}")

missing_train_years = [year for year in train_years if year not in years_in_df]
missing_test_years = [year for year in test_years if year not in years_in_df]

print(f"Missing training years: {missing_train_years}")
print(f"Missing testing years: {missing_test_years}")



# Create training and testing DataFrames
train_df = cat_df_encoded[cat_df_encoded['Year'].isin(train_years)]
test_df = cat_df_encoded[cat_df_encoded['Year'].isin(test_years)]

# Check the shape and sample data
print(f"Training DataFrame shape: {train_df.shape}")
print(f"Testing DataFrame shape: {test_df.shape}")

print("Sample of Training DataFrame:")
train_df.head()

print("Sample of Testing DataFrame:")
test_df.head()






# Separate Features (X) and Target (y)
X_train = train_df.drop(columns=['winner'])  # Features for training
y_train = train_df['winner']                # Target for training

X_test = test_df.drop(columns=['winner'])    # Features for testing
y_test = test_df['winner']                   # Target for testing

# Scaling the Data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Initialize the model
model = RandomForestClassifier(random_state=42)

# Train the model
model.fit(X_train_scaled, y_train)

# Make predictions
y_pred = model.predict(X_test_scaled)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))






from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import train_test_split



# Separate features (X) and target (y) for both training and testing DataFrames
X_train = train_df.drop('winner', axis=1)
y_train = train_df['winner']

X_test = test_df.drop('winner', axis=1)
y_test = test_df['winner']



# Initialize the Decision Tree Classifier
clf = DecisionTreeClassifier(random_state=42)

# Train the model on the training data
clf.fit(X_train, y_train)



# Predict on the test data
y_pred = clf.predict(X_test)



# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

# Generate confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
print(f"Confusion Matrix:\n{conf_matrix}")

# Generate classification report
class_report = classification_report(y_test, y_pred)
print(f"Classification Report:\n{class_report}")



import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier


# Prepare Data
X = cat_df_encoded.drop('winner', axis=1)
y = cat_df_encoded['winner']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the model
clf = DecisionTreeClassifier(random_state=42)
clf.fit(X_train, y_train)

# Make predictions
y_pred = clf.predict(X_test)

# Add the predicted_winner column to the test DataFrame
test_df = X_test.copy()  
test_df['predicted_winner'] = y_pred

# Add the true winner column for counting purposes
test_df['true_winner'] = y_test

# Aggregate count of actual winners by predicted_winner
vote_summary = test_df.groupby('predicted_winner')['true_winner'].count().reset_index()
vote_summary.rename(columns={'true_winner': 'count'}, inplace=True)

# Plotting the bar chart
plt.figure(figsize=(10, 6))
plt.bar(vote_summary['predicted_winner'].astype(str), vote_summary['count'], color=['blue', 'red'])
plt.xlabel('Predicted Winner')
plt.ylabel('Count')
plt.title('Count of Predicted Winners')
plt.xticks(ticks=[0, 1], labels=['Democrat', 'Republican'])
plt.show()






#Cross-Validation

from sklearn.model_selection import cross_val_score

# Perform cross-validation
cv_scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')

print(f"Cross-Validation Scores: {cv_scores}")
print(f"Mean CV Accuracy: {cv_scores.mean()}")



# Hyperparameter Tuning

from sklearn.model_selection import GridSearchCV

# Define the parameter grid
param_grid = {
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Initialize GridSearchCV
grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring='accuracy')

# Fit GridSearchCV
grid_search.fit(X_train, y_train)

# Best parameters and best score
print("Best Parameters:", grid_search.best_params_)
print("Best Score:", grid_search.best_score_)



# Use Ensemble Method 
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score

# Initialize and train Random Forest Classifier
rf_clf = RandomForestClassifier(random_state=42)
rf_clf.fit(X_train, y_train)

# Predict with Random Forest
y_pred_rf = rf_clf.predict(X_test)

# Calculate accuracy for Random Forest
accuracy_rf = accuracy_score(y_test, y_pred_rf)
print(f"Random Forest Accuracy: {accuracy_rf}")

# Initialize and train Gradient Boosting Classifier
gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)
gb_clf.fit(X_train, y_train)

# Predict with Gradient Boosting
y_pred_gb = gb_clf.predict(X_test)

# Calculate accuracy for Gradient Boosting
accuracy_gb = accuracy_score(y_test, y_pred_gb)
print(f"Gradient Boosting Accuracy: {accuracy_gb}")







from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("RandomForestExample") \
    .getOrCreate()



# Convert Pandas DataFrame to PySpark DataFrame
spark_df = spark.createDataFrame(cat_df_encoded)

# Show the PySpark DataFrame
spark_df.show(1)



from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.sql import SparkSession

# Initialize Spark session
spark = SparkSession.builder.appName("RandomForestExample").getOrCreate()

# Training DataFrame: years 2008, 2012, 2016
train_df = spark_df[spark_df['Year'].isin([2008, 2012, 2016])]

# Testing DataFrame: years 2022 and 2024
test_df = spark_df[spark_df['Year'].isin([2020, 2024])]



# Define feature columns
feature_columns = ["Avg_Sentiment", "total_votes", "percent", 
                   "Gross domestic product (GDP)", "Personal income",
                   "Total employment (number of jobs)", "median_age(years)",
                   "white", "black_or_african_american", "hispanic_or_latino_any_race"]

# Assemble features into a single vector
assembler = VectorAssembler(inputCols=feature_columns, outputCol="features")

train_df = assembler.transform(train_df)
test_df = assembler.transform(test_df)

# Initialize and train the model
rf = RandomForestClassifier(labelCol="winner", featuresCol="features")
model = rf.fit(train_df)

# Make predictions
predictions = model.transform(test_df)

# Evaluate the model
evaluator = MulticlassClassificationEvaluator(labelCol="winner", predictionCol="prediction", metricName="accuracy")
accuracy = evaluator.evaluate(predictions)

print(f"Accuracy: {accuracy}")




